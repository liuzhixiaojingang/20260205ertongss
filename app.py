import streamlit as st
import pandas as pd
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from PIL import Image
import io
import base64
import os
import shap
import networkx as nx
import matplotlib.patches as mpatches
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
import plotly.graph_objects as go
import plotly.io as pio

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="å„¿ç«¥çš®è‚¤æŸä¼¤è¯†åˆ«ç³»ç»Ÿ", page_icon="ğŸ‘¶ğŸ”¥", layout="wide", initial_sidebar_state="expanded")

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header { font-size: 2.5rem; color: #ff6b35; text-align: center; margin-bottom: 2rem; font-weight: bold; font-family: "Microsoft YaHei", sans-serif; }
    .sub-header { font-size: 1.5rem; color: #ff8e53; margin: 1rem 0; font-family: "Microsoft YaHei", sans-serif; }
    .feature-box { background-color: #fff5f5; padding: 1rem; border-radius: 10px; border-left: 4px solid #ff6b35; margin: 0.5rem 0; font-family: "Microsoft YaHei", sans-serif; }
    .prediction-box { background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%); padding: 1.5rem; border-radius: 15px; text-align: center; margin: 1rem 0; font-family: "Microsoft YaHei", sans-serif; }
    .analysis-box { background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); padding: 1rem; border-radius: 10px; border-left: 4px solid #2196F3; margin: 1rem 0; font-family: "Microsoft YaHei", sans-serif; }
    .setting-box { background: linear-gradient(135deg, #f0f4f8 0%, #d9e2ec 100%); padding: 1rem; border-radius: 10px; border-left: 4px solid #627d98; margin: 0.5rem 0; font-family: "Microsoft YaHei", sans-serif; }
    .guide-section { background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); padding: 1.5rem; border-radius: 10px; margin: 1rem 0; border-left: 4px solid #6c757d; font-family: "Microsoft YaHei", sans-serif; }
    .theory-box { background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%); padding: 1rem; border-radius: 8px; margin: 0.5rem 0; border-left: 4px solid #ffc107; font-family: "Microsoft YaHei", sans-serif; }
    .code-box { background-color: #f8f9fa; padding: 1rem; border-radius: 5px; border-left: 4px solid #6c757d; font-family: "Courier New", monospace; margin: 0.5rem 0; }
</style>
""", unsafe_allow_html=True)

# åŠ è½½æ¨¡å‹å‡½æ•°ï¼ˆä¿®æ”¹ä¸ºæœ¬åœ°æ¨¡å‹ï¼‰
@st.cache_resource
def load_model():
    try:
            import gdown
            # ä»Google Driveä¸‹è½½æ¨¡å‹
            model_url = "https://github.com/liuzhixiaojingang/20260205ertongss/raw/main/rf.pkl"
            model_path = "rf_model.pkl"
            
            if not os.path.exists(model_path):
                with st.spinner("æ­£åœ¨ä»äº‘ç«¯ä¸‹è½½æ¨¡å‹..."):
                    gdown.download(model_url, model_path, quiet=False)
            
            model = joblib.load(model_path)
            # è®¾ç½®ç‰¹å¾åç§°
            model.feature_names_in_ = ['BG1', 'Ascorbic acid', 'Pregnenolone sulfate', 'IL-1Î²', '5-Methoxytryptamine', 'EGF', 'BG2']
            st.success("âœ… æœ¬åœ°æ¨¡å‹åŠ è½½æˆåŠŸ")
            return model
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return None

# è·å–å›¾è¡¨å­—ä½“è®¾ç½®å‡½æ•°
def get_chart_font_settings():
    """è·å–å›¾è¡¨å­—ä½“è®¾ç½®"""
    return {
        'title_font': st.session_state.get('chart_title_font', {'family': 'Microsoft YaHei', 'size': 14, 'weight': 'bold'}),
        'axis_font': st.session_state.get('chart_axis_font', {'family': 'Microsoft YaHei', 'size': 10}),
        'tick_font': st.session_state.get('chart_tick_font', {'family': 'Microsoft YaHei', 'size': 8}),
        'label_font': st.session_state.get('chart_label_font', {'family': 'Microsoft YaHei', 'size': 9})
    }

# åº”ç”¨å›¾è¡¨å­—ä½“è®¾ç½®å‡½æ•°
def apply_chart_font_settings(ax=None, title=None, xlabel=None, ylabel=None):
    """åº”ç”¨å›¾è¡¨å­—ä½“è®¾ç½®"""
    font_settings = get_chart_font_settings()
    if ax is not None:
        if title and ax.get_title():
            ax.set_title(ax.get_title(), fontfamily=font_settings['title_font']['family'], fontsize=font_settings['title_font']['size'], fontweight=font_settings['title_font']['weight'])
        if xlabel or ax.get_xlabel():
            ax.set_xlabel(ax.get_xlabel() if not xlabel else xlabel, fontfamily=font_settings['axis_font']['family'], fontsize=font_settings['axis_font']['size'])
        if ylabel or ax.get_ylabel():
            ax.set_ylabel(ax.get_ylabel() if not ylabel else ylabel, fontfamily=font_settings['axis_font']['family'], fontsize=font_settings['axis_font']['size'])
        ax.tick_params(axis='both', which='major', labelsize=font_settings['tick_font']['size'])
        legend = ax.get_legend()
        if legend:
            for text in legend.get_texts():
                text.set_fontfamily(font_settings['label_font']['family'])
                text.set_fontsize(font_settings['label_font']['size'])

# SHAPåˆ†æå‡½æ•°
def perform_shap_analysis(model, input_data, feature_names):
    try:
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(input_data)
        prediction = model.predict(input_data)[0]
        if shap_values.ndim == 3:
            current_shap_values = shap_values[0, :, prediction]
        else:
            st.error(f"ä¸æ”¯æŒçš„SHAPç»´åº¦: {shap_values.ndim}")
            return None
        if current_shap_values.ndim > 1: current_shap_values = current_shap_values[0]
        feature_importance = np.abs(current_shap_values)
        sorted_idx = np.argsort(feature_importance)[::-1]
        return {
            'shap_values': current_shap_values, 'shap_values_3d': shap_values, 'input_data': input_data,
            'feature_importance': feature_importance, 'sorted_features': [feature_names[i] for i in sorted_idx],
            'sorted_importance': feature_importance[sorted_idx], 'prediction': prediction
        }
    except Exception as e:
        st.error(f"SHAPåˆ†æé”™è¯¯: {str(e)}")
        return None

# å›¾1: åˆå¹¶çš„SHAPåˆ†æå›¾è¡¨
def plot_combined_shap_analysis(shap_results, feature_names, burn_type_mapping):
    try:
        if shap_results is None: return None
        shap_values_3d = shap_results['shap_values_3d']
        prediction = shap_results['prediction']
        font_settings = get_chart_font_settings()
        plt.rcParams.update({
            'font.size': font_settings['tick_font']['size'],
            'axes.titlesize': font_settings['title_font']['size'],
            'axes.labelsize': font_settings['axis_font']['size'],
            'xtick.labelsize': font_settings['tick_font']['size'],
            'ytick.labelsize': font_settings['tick_font']['size'],
            'font.family': font_settings['title_font']['family']
        })
        fig, axes = plt.subplots(2, 3, figsize=(18, 10))
        fig.suptitle('SHAP Analysis: Feature Impact and Importance for All Classes', fontsize=font_settings['title_font']['size'] + 2, fontweight='bold', y=0.95, fontfamily=font_settings['title_font']['family'])
        for i in range(6):
            row, col = i // 3, i % 3
            ax = axes[row, col]
            if shap_values_3d.ndim == 3:
                class_shap_values = np.mean(shap_values_3d[:, :, i], axis=0)
                class_shap_importance = np.mean(np.abs(shap_values_3d[:, :, i]), axis=0)
            else:
                class_shap_values = shap_values_3d[i]
                class_shap_importance = np.abs(shap_values_3d[i])
            sorted_idx = np.argsort(class_shap_importance)[::-1]
            sorted_features = [feature_names[j] for j in sorted_idx]
            sorted_shap = class_shap_values[sorted_idx]
            sorted_importance = class_shap_importance[sorted_idx]
            y_pos = np.arange(len(sorted_features))
            colors = ['#ff6b6b' if val > 0 else '#4ecdc4' for val in sorted_shap]
            bars = ax.barh(y_pos, sorted_shap, color=colors, alpha=0.8, height=0.6)
            for j, (shap_val, imp_val) in enumerate(zip(sorted_shap, sorted_importance)):
                ax.scatter(imp_val if shap_val >= 0 else -imp_val, j, s=80, color='#2d3436', marker='o', alpha=0.7, zorder=5)
            ax.set_yticks(y_pos)
            ax.set_yticklabels(sorted_features, fontfamily=font_settings['tick_font']['family'])
            ax.invert_yaxis()
            ax.axvline(x=0, color='black', linestyle='-', alpha=0.5, linewidth=0.8)
            ax.set_xlabel('SHAP Value / Importance', fontsize=font_settings['axis_font']['size'], fontweight='bold', fontfamily=font_settings['axis_font']['family'])
            ax.grid(True, alpha=0.3, axis='x')
            if i == prediction:
                ax.patch.set_facecolor('#fffacd')
                ax.patch.set_alpha(0.3)
                for spine in ax.spines.values():
                    spine.set_edgecolor('red')
                    spine.set_linewidth(2)
                title_color = 'red'
                title_suffix = ' â˜…'
            else:
                title_color = 'black'
                title_suffix = ''
            ax.set_title(f'Class {i}: {burn_type_mapping[i]["en"]}{title_suffix}', fontsize=font_settings['title_font']['size'], fontweight='bold', color=title_color, pad=10, fontfamily=font_settings['title_font']['family'])
            for j, (bar, shap_val, imp_val) in enumerate(zip(bars, sorted_shap, sorted_importance)):
                width = bar.get_width()
                if abs(shap_val) > 0.001:
                    if shap_val > 0:
                        ax.text(width + 0.005, bar.get_y() + bar.get_height()/2., f'{shap_val:+.6f}', ha='left', va='center', fontsize=font_settings['label_font']['size'] - 1, color='#d63031', fontweight='bold', fontfamily=font_settings['label_font']['family'])
                    else:
                        ax.text(width - 0.005, bar.get_y() + bar.get_height()/2., f'{shap_val:+.6f}', ha='right', va='center', fontsize=font_settings['label_font']['size'] - 1, color='#00b894', fontweight='bold', fontfamily=font_settings['label_font']['family'])
                    ax.text(imp_val + 0.005 if shap_val >= 0 else -imp_val - 0.005, j, f'{imp_val:.6f}', ha='left' if shap_val >= 0 else 'right', va='center', fontsize=font_settings['label_font']['size'] - 2, color='#2d3436', fontweight='bold', fontfamily=font_settings['label_font']['family'])
        plt.tight_layout()
        plt.subplots_adjust(top=0.88)
        from matplotlib.patches import Patch
        legend_elements = [
            Patch(facecolor='#ff6b6b', alpha=0.8, label='Positive Impact'),
            Patch(facecolor='#4ecdc4', alpha=0.8, label='Negative Impact'),
            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='#2d3436', markersize=6, label='Importance Magnitude')
        ]
        fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.02), ncol=3, fontsize=font_settings['label_font']['size'], framealpha=0.9, fancybox=True, shadow=True)
        return fig
    except Exception as e:
        st.error(f"SHAPå›¾è¡¨ç»˜åˆ¶é”™è¯¯: {str(e)}")
        return None

# å›¾2: å½“å‰é¢„æµ‹ç±»åˆ«çš„ç‰¹å¾é‡è¦æ€§å›¾
def plot_current_prediction_shap(shap_results, feature_names, burn_type_mapping):
    try:
        if shap_results is None: return None
        prediction = shap_results['prediction']
        sorted_features = shap_results['sorted_features']
        sorted_importance = shap_results['sorted_importance']
        font_settings = get_chart_font_settings()
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        fig.suptitle(f'SHAP Analysis for Current Prediction: {burn_type_mapping[prediction]["en"]}', fontsize=font_settings['title_font']['size'] + 2, fontweight='bold', fontfamily=font_settings['title_font']['family'])
        y_pos = np.arange(len(sorted_features))
        colors = plt.cm.viridis(np.linspace(0, 1, len(sorted_features)))
        bars = ax1.barh(y_pos, sorted_importance, color=colors, alpha=0.8)
        ax1.set_yticks(y_pos)
        ax1.set_yticklabels(sorted_features, fontfamily=font_settings['tick_font']['family'])
        ax1.invert_yaxis()
        ax1.set_xlabel('SHAP Value Importance', fontweight='bold', fontfamily=font_settings['axis_font']['family'], fontsize=font_settings['axis_font']['size'])
        ax1.set_title('Feature Importance Ranking', fontweight='bold', fontfamily=font_settings['title_font']['family'], fontsize=font_settings['title_font']['size'])
        ax1.grid(True, alpha=0.3, axis='x')
        for bar, importance in zip(bars, sorted_importance):
            width = bar.get_width()
            ax1.text(width + 0.001, bar.get_y() + bar.get_height()/2., f'{width:.10f}', ha='left', va='center', fontsize=font_settings['label_font']['size'], fontweight='bold', fontfamily=font_settings['label_font']['family'])
        shap_values = shap_results['shap_values']
        positive_count = np.sum(shap_values > 0)
        negative_count = np.sum(shap_values < 0)
        neutral_count = np.sum(shap_values == 0)
        sizes = [positive_count, negative_count, neutral_count]
        labels = ['Positive Impact', 'Negative Impact', 'No Impact']
        colors = ['#ff6b6b', '#4ecdc4', '#95a5a6']
        if sum(sizes) > 0:
            wedges, texts, autotexts = ax2.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90, textprops={'fontfamily': font_settings['label_font']['family'], 'fontsize': font_settings['label_font']['size']})
            for autotext in autotexts:
                autotext.set_color('white')
                autotext.set_fontweight('bold')
        else:
            ax2.text(0.5, 0.5, 'No significant\nSHAP values', ha='center', va='center', transform=ax2.transAxes, fontsize=font_settings['label_font']['size'], fontfamily=font_settings['label_font']['family'])
        ax2.set_title('SHAP Value Distribution', fontweight='bold', fontfamily=font_settings['title_font']['family'], fontsize=font_settings['title_font']['size'])
        apply_chart_font_settings(ax1, xlabel='SHAP Value Importance')
        apply_chart_font_settings(ax2)
        plt.tight_layout()
        return fig
    except Exception as e:
        st.error(f"å½“å‰é¢„æµ‹SHAPå›¾è¡¨ç»˜åˆ¶é”™è¯¯: {str(e)}")
        return None

# ä¼˜åŒ–çš„å›¾ç½‘ç»œåˆ†æ
def perform_graph_analysis(feature_values, feature_names, prediction, burn_type_mapping):
    try:
        G = nx.Graph()
        for i, feature in enumerate(feature_names):
            G.add_node(feature, value=feature_values[i], importance=abs(feature_values[i]))
        for i in range(len(feature_names)):
            for j in range(i+1, len(feature_names)):
                correlation = 1 - abs(feature_values[i] - feature_values[j]) / (abs(feature_values[i]) + abs(feature_values[j]) + 1e-8)
                if correlation > 0.3:
                    G.add_edge(feature_names[i], feature_names[j], weight=correlation)
        degree_centrality = nx.degree_centrality(G)
        betweenness_centrality = nx.betweenness_centrality(G)
        closeness_centrality = nx.closeness_centrality(G)
        return {
            'graph': G, 'degree_centrality': degree_centrality, 'betweenness_centrality': betweenness_centrality,
            'closeness_centrality': closeness_centrality, 'node_importance': {feature: abs(val) for feature, val in zip(feature_names, feature_values)}
        }
    except Exception as e:
        st.warning(f"å›¾ç½‘ç»œåˆ†æé‡åˆ°é—®é¢˜: {str(e)}")
        return None

# ä¼˜åŒ–çš„å›¾ç½‘ç»œå¯è§†åŒ–
def plot_optimized_graph_analysis(graph_results, feature_names, burn_info):
    try:
        if graph_results is None: return None
        G = graph_results['graph']
        font_settings = get_chart_font_settings()
        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 6))
        fig.suptitle(f'Feature Network Analysis - {burn_info["cn"]}', fontsize=font_settings['title_font']['size'] + 2, fontweight='bold', fontfamily=font_settings['title_font']['family'])
        fig.patch.set_facecolor('white')
        ax1.set_facecolor('white')
        pos = nx.spring_layout(G, seed=42, k=3, iterations=200)
        node_colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFD700', '#9370DB', '#20B2AA']
        node_color_map = {feature: node_colors[i] for i, feature in enumerate(feature_names)}
        node_sizes = [3000 + 2000 * graph_results['node_importance'][node] for node in G.nodes()]
        node_colors_list = [node_color_map[node] for node in G.nodes()]
        nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors_list, alpha=0.9, ax=ax1, edgecolors='black', linewidths=2)
        edges = G.edges()
        weights = [G[u][v]['weight'] for u,v in edges]
        edge_colors = ['#2C3E50' for _ in edges]
        edge_widths = [w * 5 + 1 for w in weights]
        nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=[min(w * 1.5, 0.8) for w in weights], edge_color=edge_colors, ax=ax1, style='solid')
        labels = {node: node for node in G.nodes()}
        nx.draw_networkx_labels(G, pos, labels, font_size=12, font_weight='bold', ax=ax1, font_family=font_settings['label_font']['family'], bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=1))
        ax1.set_title('Network Topology', fontsize=font_settings['title_font']['size'], fontweight='bold', fontfamily=font_settings['title_font']['family'])
        ax1.axis('off')
        centrality_data = {
            'Feature': list(graph_results['degree_centrality'].keys()),
            'Degree': list(graph_results['degree_centrality'].values()),
            'Betweenness': list(graph_results['betweenness_centrality'].values()),
            'Closeness': list(graph_results['closeness_centrality'].values())
        }
        df = pd.DataFrame(centrality_data)
        categories = list(df['Feature'])
        N = len(categories)
        angles = [n / float(N) * 2 * np.pi for n in range(N)]
        angles += angles[:1]
        ax2 = plt.subplot(132, polar=True)
        ax2.set_facecolor('white')
        ax2.set_theta_offset(np.pi / 2)
        ax2.set_theta_direction(-1)
        ax2.set_xticks(angles[:-1])
        ax2.set_xticklabels(categories, fontfamily=font_settings['tick_font']['family'])
        values = df['Degree'].values.tolist()
        values += values[:1]
        ax2.plot(angles, values, 'o-', linewidth=2, label='Degree Centrality', color='#e74c3c')
        ax2.fill(angles, values, alpha=0.25, color='#e74c3c')
        values = df['Betweenness'].values.tolist()
        values += values[:1]
        ax2.plot(angles, values, 'o-', linewidth=2, label='Betweenness Centrality', color='#3498db')
        ax2.fill(angles, values, alpha=0.25, color='#3498db')
        values = df['Closeness'].values.tolist()
        values += values[:1]
        ax2.plot(angles, values, 'o-', linewidth=2, label='Closeness Centrality', color='#2ecc71')
        ax2.fill(angles, values, alpha=0.25, color='#2ecc71')
        ax2.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0), prop={'family': font_settings['label_font']['family'], 'size': font_settings['label_font']['size']})
        ax2.set_title('Centrality Analysis Radar Chart', fontsize=font_settings['title_font']['size'], fontweight='bold', fontfamily=font_settings['title_font']['family'])
        ax3.set_facecolor('white')
        correlation_matrix = np.zeros((len(feature_names), len(feature_names)))
        for i, feat1 in enumerate(feature_names):
            for j, feat2 in enumerate(feature_names):
                if feat1 == feat2:
                    correlation_matrix[i, j] = 1.0
                elif G.has_edge(feat1, feat2):
                    correlation_matrix[i, j] = G[feat1][feat2]['weight']
                else:
                    correlation_matrix[i, j] = 0.0
        im = ax3.imshow(correlation_matrix, cmap='RdYlBu_r', vmin=0, vmax=1)
        ax3.set_xticks(range(len(feature_names)))
        ax3.set_yticks(range(len(feature_names)))
        ax3.set_xticklabels(feature_names, rotation=45, fontfamily=font_settings['tick_font']['family'])
        ax3.set_yticklabels(feature_names, fontfamily=font_settings['tick_font']['family'])
        ax3.set_title('Feature Correlation Heatmap', fontsize=font_settings['title_font']['size'], fontweight='bold', fontfamily=font_settings['title_font']['family'])
        for i in range(len(feature_names)):
            for j in range(len(feature_names)):
                text = ax3.text(j, i, f'{correlation_matrix[i, j]:.6f}', ha="center", va="center", color="black", fontsize=font_settings['label_font']['size'] - 1, fontweight='bold', fontfamily=font_settings['label_font']['family'])
        plt.colorbar(im, ax=ax3, fraction=0.046, pad=0.04)
        apply_chart_font_settings(ax1)
        apply_chart_font_settings(ax2)
        apply_chart_font_settings(ax3)
        plt.tight_layout()
        return fig
    except Exception as e:
        st.warning(f"å›¾ç½‘ç»œå¯è§†åŒ–é”™è¯¯: {str(e)}")
        return None

# åäº‹å®åˆ†æå‡½æ•°
def perform_counterfactual_analysis(model, input_data, original_prediction, feature_names, burn_type_mapping):
    try:
        if original_prediction == 0:
            return {
                'all_counterfactuals': [],
                'normal_tissue_suggestions': [],
                'original_prediction': original_prediction,
                'skip_analysis': True
            }
        base_values = input_data.iloc[0].values
        counterfactuals = []
        normal_tissue_suggestions = []
        for i, feature in enumerate(feature_names):
            for change_factor in [0.5, 0.7, 1.3, 1.5, 2.0]:
                modified_data = base_values.copy()
                modified_data[i] = modified_data[i] * change_factor
                modified_df = pd.DataFrame([modified_data], columns=feature_names)
                new_prediction = model.predict(modified_df)[0]
                new_probability = model.predict_proba(modified_df)[0][new_prediction]
                if new_prediction != original_prediction:
                    counterfactuals.append({
                        'changed_feature': feature, 'change_factor': change_factor,
                        'new_prediction': new_prediction, 'confidence': new_probability,
                        'required_change': f"{change_factor:.1f}x", 'original_value': base_values[i],
                        'new_value': modified_data[i], 'change_direction': "å¢åŠ " if change_factor > 1 else "å‡å°‘"
                    })
                if new_prediction == 0:
                    normal_tissue_suggestions.append({
                        'feature': feature, 'change_factor': change_factor,
                        'confidence': new_probability, 'required_change': f"{change_factor:.1f}x",
                        'original_value': base_values[i], 'new_value': modified_data[i],
                        'change_direction': "å¢åŠ " if change_factor > 1 else "å‡å°‘"
                    })
        normal_tissue_suggestions.sort(key=lambda x: x['confidence'], reverse=True)
        counterfactuals.sort(key=lambda x: x['confidence'], reverse=True)
        return {
            'all_counterfactuals': counterfactuals[:5],
            'normal_tissue_suggestions': normal_tissue_suggestions[:3],
            'original_prediction': original_prediction,
            'skip_analysis': False
        }
    except Exception as e:
        st.warning(f"åäº‹å®åˆ†æé‡åˆ°é—®é¢˜: {str(e)}")
        return {'all_counterfactuals': [], 'normal_tissue_suggestions': [], 'original_prediction': original_prediction, 'skip_analysis': False}

# ä¼˜åŒ–çš„åäº‹å®åˆ†æå¯è§†åŒ–
def plot_optimized_counterfactual_analysis(counterfactual_results, burn_type_mapping):
    try:
        if not counterfactual_results or counterfactual_results.get('skip_analysis', False):
            return None
        suggestions = counterfactual_results['normal_tissue_suggestions']
        if not suggestions:
            return None
        font_settings = get_chart_font_settings()
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        fig.suptitle('Counterfactual Analysis - Normal Tissue Recovery Strategies', fontsize=font_settings['title_font']['size'] + 2, fontweight='bold', fontfamily=font_settings['title_font']['family'])
        features = [s['feature'] for s in suggestions]
        confidences = [s['confidence'] for s in suggestions]
        change_factors = [s['change_factor'] for s in suggestions]
        colors = ['#4CAF50' if factor > 1 else '#F44336' for factor in change_factors]
        bars = ax1.barh(features, confidences, color=colors, alpha=0.8, height=0.6)
        ax1.set_xlabel('Confidence Level', fontweight='bold', fontfamily=font_settings['axis_font']['family'], fontsize=font_settings['axis_font']['size'])
        ax1.set_title('Recovery Strategy Effectiveness', fontsize=font_settings['title_font']['size'], fontweight='bold', fontfamily=font_settings['title_font']['family'])
        ax1.set_xlim(0, 1)
        ax1.grid(True, alpha=0.3, axis='x')
        for bar, factor, conf in zip(bars, change_factors, confidences):
            width = bar.get_width()
            ax1.text(width + 0.02, bar.get_y() + bar.get_height()/2, f'{factor:.1f}x\n{conf:.1%}', ha='left', va='center', fontweight='bold', fontsize=font_settings['label_font']['size'], fontfamily=font_settings['label_font']['family'])
        features = [s['feature'] for s in suggestions]
        original_vals = [s['original_value'] for s in suggestions]
        target_vals = [s['new_value'] for s in suggestions]
        changes = [s['change_factor'] for s in suggestions]
        x_pos = np.arange(len(features))
        width = 0.35
        bars1 = ax2.bar(x_pos - width/2, original_vals, width, label='Current Value', color='#2196F3', alpha=0.7)
        bars2 = ax2.bar(x_pos + width/2, target_vals, width, label='Target Value', color='#4CAF50', alpha=0.7)
        for i, (orig, target, change) in enumerate(zip(original_vals, target_vals, changes)):
            arrow_x = i
            arrow_y1 = orig
            arrow_y2 = target
            arrow_color = 'red' if change > 1 else 'blue'
            arrow_style = '->' if change > 1 else '<-'
            ax2.annotate('', xy=(arrow_x + width/2, arrow_y2), xytext=(arrow_x - width/2, arrow_y1), arrowprops=dict(arrowstyle=arrow_style, color=arrow_color, lw=2))
        ax2.set_xlabel('Features', fontweight='bold', fontfamily=font_settings['axis_font']['family'], fontsize=font_settings['axis_font']['size'])
        ax2.set_ylabel('Values', fontweight='bold', fontfamily=font_settings['axis_font']['family'], fontsize=font_settings['axis_font']['size'])
        ax2.set_title('Feature Adjustment Pathways', fontsize=font_settings['title_font']['size'], fontweight='bold', fontfamily=font_settings['title_font']['family'])
        ax2.set_xticks(x_pos)
        ax2.set_xticklabels(features, rotation=45, fontfamily=font_settings['tick_font']['family'])
        ax2.legend(prop={'family': font_settings['label_font']['family'], 'size': font_settings['label_font']['size']})
        ax2.grid(True, alpha=0.3)
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01 * max(target_vals), f'{height:.10f}', ha='center', va='bottom', fontsize=font_settings['label_font']['size'] - 1, fontweight='bold', fontfamily=font_settings['label_font']['family'])
        apply_chart_font_settings(ax1, xlabel='Confidence Level')
        apply_chart_font_settings(ax2, xlabel='Features', ylabel='Values')
        plt.tight_layout()
        return fig
    except Exception as e:
        st.warning(f"åäº‹å®å›¾è¡¨ç»˜åˆ¶é”™è¯¯: {str(e)}")
        return None

# ç”ŸæˆåŒ»ç–—æ£€æµ‹æŠ¥å‘Šçš„å‡½æ•°
def generate_medical_report(input_data, prediction, probabilities, shap_results, graph_results, counterfactual_results, burn_type_mapping, feature_names, language='ä¸­æ–‡'):
    """ç”Ÿæˆè¯¦ç»†çš„åŒ»ç–—æ£€æµ‹æŠ¥å‘Š"""
    burn_info = burn_type_mapping[prediction]
    if language == 'ä¸­æ–‡':
        report = f"""çƒ§ä¼¤æ™ºèƒ½è¯†åˆ«ç³»ç»Ÿ - åŒ»ç–—æ£€æµ‹æŠ¥å‘Š
==================================================
ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
ã€åŸºæœ¬ä¿¡æ¯ã€‘
æ‚£è€…æ ·æœ¬ç¼–å·: {pd.Timestamp.now().strftime('%Y%m%d%H%M%S')}
åˆ†ææ¨¡å‹: éšæœºæ£®æ—å¤šåˆ†ç±»æ¨¡å‹
æ•°æ®ç²¾åº¦: å°æ•°ç‚¹å10ä½
ã€è¾“å…¥å‚æ•°è¯¦ç»†æ•°æ®ã€‘
BG1 (ç”Ÿç‰©æ ‡å¿—ç‰©1): {input_data.iloc[0, 0]:.10f}
Ascorbic acid (æŠ—åè¡€é…¸): {input_data.iloc[0, 1]:.10f}
Pregnenolone sulfate (å­•çƒ¯é†‡é…®ç¡«é…¸é…¯): {input_data.iloc[0, 2]:.10f}
IL-1Î² (ç™½ç»†èƒä»‹ç´ -1Î²): {input_data.iloc[0, 3]:.10f} pg/mL
5-Methoxytryptamine (5-ç”²æ°§åŸºè‰²èƒº): {input_data.iloc[0, 4]:.10f}
EGF (è¡¨çš®ç”Ÿé•¿å› å­): {input_data.iloc[0, 5]:.10f} pg/mL
BG2 (ç”Ÿç‰©æ ‡å¿—ç‰©2): {input_data.iloc[0, 6]:.10f}
ã€è¯Šæ–­ç»“æœã€‘
ä¸»è¦è¯Šæ–­: {burn_info['cn']} ({burn_info['en']})
ç½®ä¿¡åº¦: {probabilities[prediction]:.2%}
ä¸´åºŠæè¿°: {burn_info['description']}
ã€æ¦‚ç‡åˆ†å¸ƒåˆ†æã€‘
"""
        for i, prob in enumerate(probabilities):
            report += f"{burn_type_mapping[i]['cn']}: {prob:.2%}\n"
        report += f"\nã€ç”Ÿç‰©æ ‡å¿—ç‰©ä¸´åºŠæ„ä¹‰åˆ†æã€‘\n" + "="*50 + "\n"
        if shap_results:
            shap_values = shap_results['shap_values']
            for i, feature in enumerate(feature_names):
                shap_val = shap_values[i]
                original_val = input_data.iloc[0, i]
                report += f"\n{feature}åˆ†æ:\n"
                report += f"- å½“å‰æ°´å¹³: {original_val:.10f}\n"
                report += f"- å¯¹è¯Šæ–­å½±å“: {shap_val:+.6f} "
                if shap_val > 0.01:
                    report += "(æ˜¾è‘—æ­£å‘å½±å“ â†’ ä¿ƒè¿›è¯¥è¯Šæ–­)\n"
                elif shap_val < -0.01:
                    report += "(æ˜¾è‘—è´Ÿå‘å½±å“ â†’ æŠ‘åˆ¶è¯¥è¯Šæ–­)\n"
                else:
                    report += "(å½±å“è¾ƒå°)\n"
        if shap_results:
            report += f"\nã€SHAPå¯è§£é‡Šæ€§åˆ†æã€‘\n" + "="*50 + "\n"
            report += "ç‰¹å¾é‡è¦æ€§æ’åº (åŸºäºSHAPç»å¯¹å€¼):\n"
            for i, (feature, importance) in enumerate(zip(shap_results['sorted_features'], shap_results['sorted_importance'])):
                report += f"{i+1}. {feature}: {importance:.10f}\n"
        if graph_results:
            report += f"\nã€å›¾ç½‘ç»œåˆ†æç»“æœã€‘\n" + "="*50 + "\n"
            report += f"ç½‘ç»œèŠ‚ç‚¹æ•°: {len(graph_results['graph'].nodes())}\n"
            report += f"ç½‘ç»œè¾¹æ•°: {len(graph_results['graph'].edges())}\n"
            report += "ç‰¹å¾ä¸­å¿ƒæ€§åˆ†æ:\n"
            for feature in graph_results['degree_centrality']:
                report += f"- {feature}: åº¦ä¸­å¿ƒæ€§={graph_results['degree_centrality'][feature]:.6f}, ä»‹æ•°ä¸­å¿ƒæ€§={graph_results['betweenness_centrality'][feature]:.6f}, ç´§å¯†ä¸­å¿ƒæ€§={graph_results['closeness_centrality'][feature]:.6f}\n"
        if counterfactual_results and not counterfactual_results.get('skip_analysis', False) and counterfactual_results['normal_tissue_suggestions']:
            report += f"\nã€åäº‹å®åˆ†æä¸æ²»ç–—å»ºè®®ã€‘\n" + "="*50 + "\n"
            report += "åŸºäºæ¨¡å‹é¢„æµ‹çš„å¹²é¢„ç­–ç•¥åˆ†æ:\n\n"
            for i, suggestion in enumerate(counterfactual_results['normal_tissue_suggestions'][:3], 1):
                report += f"æ²»ç–—æ–¹æ¡ˆ {i}:\n"
                report += f"- è°ƒæ•´ç›®æ ‡: å°†{suggestion['feature']}{suggestion['change_direction']}{suggestion['required_change']}\n"
                report += f"- å…·ä½“æ•°å€¼: {suggestion['original_value']:.10f} â†’ {suggestion['new_value']:.10f}\n"
                report += f"- é¢„æœŸæ•ˆæœç½®ä¿¡åº¦: {suggestion['confidence']:.2%}\n"
                report += f"- ä¸´åºŠæ„ä¹‰: é¢„æµ‹ä»{burn_type_mapping[counterfactual_results['original_prediction']]['cn']}æ¢å¤åˆ°æ­£å¸¸ç»„ç»‡\n\n"
        report += f"\nã€ä¸´åºŠæ²»ç–—å»ºè®®ä¸æ³¨æ„äº‹é¡¹ã€‘\n" + "="*50 + "\n"
        if prediction == 0:
            report += "å½“å‰è¯Šæ–­ä¸ºæ­£å¸¸ç»„ç»‡ï¼Œæ— éœ€ç‰¹æ®Šæ²»ç–—ã€‚\n"
            report += "å»ºè®®:\n"
            report += "- å®šæœŸç›‘æµ‹ç”Ÿç‰©æ ‡å¿—ç‰©æ°´å¹³\n"
            report += "- ä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼\n"
            report += "- é¿å…çƒ§ä¼¤é£é™©å› ç´ \n"
        else:
            report += f"é’ˆå¯¹{burn_info['cn']}çš„æ²»ç–—å»ºè®®:\n"
            if prediction in [1, 2]:
                report += "- ç«‹å³è¿›è¡Œä¼¤å£æ¸…æ´å’Œæ¶ˆæ¯’\n"
                report += "- ä½¿ç”¨é€‚å½“çš„æ•·æ–™ä¿æŠ¤åˆ›é¢\n"
                report += "- è€ƒè™‘ä½¿ç”¨ç”Ÿé•¿å› å­ä¿ƒè¿›æ„ˆåˆ\n"
                report += "- å®šæœŸæ›´æ¢æ•·æ–™ï¼Œç›‘æµ‹æ„ŸæŸ“è¿¹è±¡\n"
                report += "- å¦‚IL-1Î²æ°´å¹³é«˜ï¼Œè€ƒè™‘æŠ—ç‚æ²»ç–—\n"
            elif prediction == 3:
                report += "- éœ€è¦å¤–ç§‘æ¸…åˆ›å’Œæ¤çš®æ‰‹æœ¯\n"
                report += "- å…¨èº«æŠ—æ„ŸæŸ“æ²»ç–—\n"
                report += "- è¥å…»æ”¯æŒï¼Œä¿ƒè¿›ç»„ç»‡ä¿®å¤\n"
                report += "- ç–¼ç—›ç®¡ç†å’Œç‚ç—‡æ§åˆ¶\n"
                report += "- é•¿æœŸåº·å¤å’ŒåŠŸèƒ½è®­ç»ƒ\n"
            elif prediction == 4:
                report += "- è¯„ä¼°æ·±éƒ¨ç»„ç»‡æŸä¼¤ç¨‹åº¦\n"
                report += "- ç›‘æµ‹å¿ƒç”µå›¾å’Œè‚Œé…¸æ¿€é…¶\n"
                report += "- ç§¯ææ¸…åˆ›ï¼Œé¢„é˜²æ„ŸæŸ“\n"
                report += "- æ³¨æ„å¯èƒ½çš„å¹¶å‘ç—‡\n"
                report += "- å¤šå­¦ç§‘å›¢é˜Ÿåä½œæ²»ç–—\n"
            elif prediction == 5:
                report += "- è¯„ä¼°å¸å…¥æ€§æŸä¼¤é£é™©\n"
                report += "- å…¨é¢æ¸…åˆ›å’Œçƒ§ä¼¤æŠ¤ç†\n"
                report += "- é¢„é˜²æ„ŸæŸ“å’Œè´¥è¡€ç—‡\n"
                report += "- è¥å…»æ”¯æŒå’Œä»£è°¢ç®¡ç†\n"
                report += "- å¿ƒç†æ”¯æŒå’Œåº·å¤æ²»ç–—\n"
        report += f"\nã€æŠ¥å‘Šè¯´æ˜ã€‘\n" + "="*50 + "\n"
        report += "1. æœ¬æŠ¥å‘ŠåŸºäºæœºå™¨å­¦ä¹ æ¨¡å‹åˆ†æç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ\n"
        report += "2. ä¸´åºŠè¯Šæ–­éœ€ç»“åˆä¸´åºŠè¡¨ç°å’ŒåŒ»å¸ˆåˆ¤æ–­\n"
        report += "3. æ²»ç–—å»ºè®®éœ€åœ¨ä¸“ä¸šåŒ»å¸ˆæŒ‡å¯¼ä¸‹å®æ–½\n"
        report += "4. å®šæœŸéšè®¿å’Œç›‘æµ‹å¯¹æ²»ç–—æ•ˆæœè‡³å…³é‡è¦\n"
    else:
        report = f"""Burn Intelligent Recognition System - Medical Analysis Report
==================================================
Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
ã€Basic Informationã€‘
Sample ID: {pd.Timestamp.now().strftime('%Y%m%d%H%M%S')}
Analysis Model: Random Forest Multi-class Model
Data Precision: 10 decimal places
ã€Input Parametersã€‘
BG1 (Biomarker 1): {input_data.iloc[0, 0]:.10f}
Ascorbic acid: {input_data.iloc[0, 1]:.10f}
Pregnenolone sulfate: {input_data.iloc[0, 2]:.10f}
IL-1Î² (Interleukin-1Î²): {input_data.iloc[0, 3]:.10f} pg/mL
5-Methoxytryptamine: {input_data.iloc[0, 4]:.10f}
EGF (Epidermal Growth Factor): {input_data.iloc[0, 5]:.10f} pg/mL
BG2 (Biomarker 2): {input_data.iloc[0, 6]:.10f}
ã€Diagnosis Resultsã€‘
Primary Diagnosis: {burn_info['en']} ({burn_info['cn']})
Confidence: {probabilities[prediction]:.2%}
Clinical Description: {burn_info['description_en']}
ã€Probability Distribution Analysisã€‘
"""
        for i, prob in enumerate(probabilities):
            report += f"{burn_type_mapping[i]['en']}: {prob:.2%}\n"
    return report

# 3Dçš®è‚¤æ¨¡å‹å‡½æ•°
def create_skin_3d_model_with_burn_depth(prediction=None, probabilities=None, burn_color='#FF4500', burn_opacity=0.7):
    """åˆ›å»ºå¸¦æœ‰çƒ§ä¼¤æ·±åº¦æ ‡æ³¨çš„3Dçš®è‚¤æ¨¡å‹"""
    fig = go.Figure()
    
    # å®šä¹‰çš®è‚¤å„å±‚
    epidermis_depth = 0.2
    dermis_depth = 2.0
    subcutaneous_depth = 5.0
    
    # ç»˜åˆ¶çš®è‚¤å„å±‚
    epidermis_vertices_x = [0, 10, 10, 0, 0, 10, 10, 0]
    epidermis_vertices_y = [0, 0, 10, 10, 0, 0, 10, 10]
    epidermis_vertices_z = [0, 0, 0, 0, epidermis_depth, epidermis_depth, epidermis_depth, epidermis_depth]
    epidermis_i = [0, 0, 0, 0, 5, 7, 7, 5, 6, 1, 4, 2]
    epidermis_j = [3, 1, 2, 4, 1, 6, 3, 4, 0, 2, 5, 3]
    epidermis_k = [1, 2, 3, 7, 4, 3, 2, 0, 5, 6, 0, 6]
    
    fig.add_trace(go.Mesh3d(
        x=epidermis_vertices_x, y=epidermis_vertices_y, z=epidermis_vertices_z,
        i=epidermis_i, j=epidermis_j, k=epidermis_k,
        name='è¡¨çš®å±‚ (0-0.2mm)', color='#FFFACD', opacity=0.6, showlegend=False
    ))
    
    dermis_vertices_z = [epidermis_depth] * 4 + [dermis_depth] * 4
    fig.add_trace(go.Mesh3d(
        x=epidermis_vertices_x, y=epidermis_vertices_y, z=dermis_vertices_z,
        i=epidermis_i, j=epidermis_j, k=epidermis_k,
        name='çœŸçš®å±‚ (0.2-2.0mm)', color='#FF6B6B', opacity=0.7, showlegend=False
    ))
    
    subcutaneous_vertices_z = [dermis_depth] * 4 + [subcutaneous_depth] * 4
    fig.add_trace(go.Mesh3d(
        x=epidermis_vertices_x, y=epidermis_vertices_y, z=subcutaneous_vertices_z,
        i=epidermis_i, j=epidermis_j, k=epidermis_k,
        name='çš®ä¸‹ç»„ç»‡ (2.0-5.0mm)', color='#FFA07A', opacity=0.5, showlegend=False
    ))
    
    # åˆ†ç•Œé¢
    x_interface = np.linspace(0, 10, 20)
    y_interface = np.linspace(0, 10, 20)
    X_interface, Y_interface = np.meshgrid(x_interface, y_interface)
    
    Z_skin_surface = np.zeros_like(X_interface)
    fig.add_trace(go.Surface(z=Z_skin_surface, x=X_interface, y=Y_interface, name='çš®è‚¤è¡¨é¢',
        colorscale=[[0, '#FAEBD7'], [1, '#F5DEB3']], opacity=0.9, showscale=False, showlegend=False))
    
    Z_epidermis_dermis_interface = np.ones_like(X_interface) * epidermis_depth
    fig.add_trace(go.Surface(z=Z_epidermis_dermis_interface, x=X_interface, y=Y_interface, name='è¡¨çš®-çœŸçš®åˆ†ç•Œé¢',
        colorscale=[[0, '#F0E68C'], [1, '#DAA520']], opacity=0.8, showscale=False, showlegend=False))
    
    Z_dermis_subcutaneous_interface = np.ones_like(X_interface) * dermis_depth
    fig.add_trace(go.Surface(z=Z_dermis_subcutaneous_interface, x=X_interface, y=Y_interface, name='çœŸçš®-çš®ä¸‹ç»„ç»‡åˆ†ç•Œé¢',
        colorscale=[[0, '#FF6347'], [1, '#B22222']], opacity=0.8, showscale=False, showlegend=False))
    
    # æ ¹æ®é¢„æµ‹ç»“æœæ·»åŠ çƒ§ä¼¤åŒºåŸŸ
    burn_regions = []
    if prediction is not None and prediction > 0:  # ä¸æ˜¯æ­£å¸¸ç»„ç»‡
        burn_depth_map = {
            1: 0.8,   # æµ…è¡¨éƒ¨åˆ†åšåº¦çƒ§ä¼¤
            2: 1.5,   # æ·±å±‚éƒ¨åˆ†åšåº¦çƒ§ä¼¤
            3: 3.5,   # å…¨å±‚åšåº¦çƒ§ä¼¤
            4: 4.0,   # ç”µå‡»çƒ§ä¼¤
            5: 2.5    # ç«ç„°çƒ§ä¼¤
        }
        burn_depth = burn_depth_map.get(prediction, 1.0)
        
        # åˆ›å»ºåŠçƒå½¢çŠ¶çƒ§ä¼¤åŒºåŸŸ
        burn_center_x, burn_center_y = 5, 5
        radius = 2.0
        phi = np.linspace(0, np.pi/2, 15)  # ä»0åˆ°90åº¦
        theta = np.linspace(0, 2*np.pi, 30)

        # åˆ›å»ºåŠçƒç½‘æ ¼
        phi_grid, theta_grid = np.meshgrid(phi, theta)
        x = burn_center_x + radius * np.sin(phi_grid) * np.cos(theta_grid)
        y = burn_center_y + radius * np.sin(phi_grid) * np.sin(theta_grid)
        z = burn_depth * np.cos(phi_grid)  # åŠçƒå½¢çŠ¶

        # æ·»åŠ åŠçƒçƒ§ä¼¤åŒºåŸŸ
        fig.add_trace(go.Surface(
            x=x, y=y, z=z,
            colorscale=[[0, '#FF4500'], [1, '#FF6347']],
            opacity=0.7,
            showscale=False,
            name=f'çƒ§ä¼¤åŒºåŸŸ'
        ))
        
        # ä¿®æ”¹Surfaceçš„é¢œè‰²å’Œé€æ˜åº¦å‚æ•°
        colorscale=[[0, burn_color], [1, burn_color]],
        opacity=burn_opacity,
        
        # æ·»åŠ çƒ§ä¼¤æ·±åº¦æ ‡æ³¨
        burn_regions.append({
            'x': burn_center_x, 'y': burn_center_y, 'z': burn_depth/2,
            'text': f"{burn_type_mapping[prediction]['cn']}\næ·±åº¦: {burn_depth}mm\nç½®ä¿¡åº¦: {probabilities[prediction]:.2%}"
        })
    
    annotations = []
    
    # çš®è‚¤å±‚åç§°æ ‡æ³¨
    layer_labels = [
        dict(x=0, y=9, z=0.1, text="<b>è¡¨çš®å±‚</b><br>(0-0.2mm)", showarrow=True, arrowhead=1, arrowwidth=2, font=dict(size=12, color="#8B6914")),
        dict(x=0, y=9, z=1.0, text="<b>çœŸçš®å±‚</b><br>(0.2-2.0mm)", showarrow=True, arrowhead=1, arrowwidth=2, font=dict(size=12, color="#8B0000")),
        dict(x=0, y=9, z=3.5, text="<b>çš®ä¸‹ç»„ç»‡</b><br>(2.0-5.0mm)", showarrow=True, arrowhead=1, arrowwidth=2, font=dict(size=12, color="#8B4500")),
    ]
    
    annotations.extend(layer_labels)
    
    # çƒ§ä¼¤åŒºåŸŸæ ‡æ³¨
    for region in burn_regions:
        annotations.append(dict(
            x=region['x'], y=region['y'], z=region['z'],
            text=region['text'],
            showarrow=True, arrowhead=2, arrowwidth=2, arrowcolor='red',
            font=dict(size=12, color="red"), bgcolor="rgba(255, 255, 255, 0.8)"
        ))
    
    # é…ç½®å›¾è¡¨å¸ƒå±€
    title_text = "3Dçš®è‚¤æ¨¡å‹ - çƒ§ä¼¤æ·±åº¦åˆ†ç±»ç³»ç»Ÿ"
    if prediction is not None:
        burn_info = burn_type_mapping[prediction]
        title_text = f"3Dçš®è‚¤æ¨¡å‹ - çƒ§ä¼¤è¯Šæ–­ç»“æœ: {burn_info['cn']} ({burn_info['en']})"
    
    fig.update_layout(
        title={'text': title_text, 'x': 0.5, 'font': dict(size=20, color='darkblue')},
        scene=dict(
            xaxis=dict(title='çš®è‚¤è¡¨é¢ (mm)', range=[0, 12], showgrid=True, gridcolor='lightgray', backgroundcolor='rgba(240, 240, 240, 0.1)'),
            yaxis=dict(title='çš®è‚¤è¡¨é¢ (mm)', range=[0, 12], showgrid=True, gridcolor='lightgray'),
            zaxis=dict(title='æ·±åº¦ (mm)', range=[subcutaneous_depth, 0], showgrid=True, gridcolor='lightgray'),
            camera=dict(eye=dict(x=1.5, y=1.5, z=1.5), up=dict(x=0, y=0, z=1)),
            aspectmode='manual', aspectratio=dict(x=1, y=1, z=0.8),
            annotations=annotations
        ),
        showlegend=False, width=1000, height=700
    )
    
    return fig

# è‡ªåŠ¨åŠ è½½æ¨¡å‹
if 'model' not in st.session_state:
    with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹..."): 
        st.session_state.model = load_model()

# çƒ§ä¼¤ç±»å‹æ˜ å°„
burn_type_mapping = {
    0: {"en": "Normal", "cn": "æ­£å¸¸ç»„ç»‡", "color": "#4CAF50", "description": "æ­£å¸¸çš®è‚¤ç»„ç»‡", "description_en": "Normal skin tissue"},
    1: {"en": "Superficial partial-thickness", "cn": "æµ…è¡¨éƒ¨åˆ†åšåº¦çƒ§ä¼¤", "color": "#FF9800", "description": "è¡¨çš®å’Œéƒ¨åˆ†çœŸçš®å—æŸ", "description_en": "Epidermis and partial dermis damage"},
    2: {"en": "Deep partial-thickness", "cn": "æ·±å±‚éƒ¨åˆ†åšåº¦çƒ§ä¼¤", "color": "#FF5722", "description": "çœŸçš®æ·±å±‚å—æŸ", "description_en": "Deep dermis damage"},
    3: {"en": "Full-thickness", "cn": "å…¨å±‚åšåº¦çƒ§ä¼¤", "color": "#F44336", "description": "çš®è‚¤å…¨å±‚å—æŸ", "description_en": "Full-thickness skin damage"},
    4: {"en": "Electrical", "cn": "ç”µå‡»çƒ§ä¼¤", "color": "#9C27B0", "description": "ç”µå‡»å¯¼è‡´çš„ç»„ç»‡æŸä¼¤", "description_en": "Tissue damage caused by electric shock"},
    5: {"en": "Flame", "cn": "ç«ç„°çƒ§ä¼¤", "color": "#795548", "description": "ç«ç„°ç›´æ¥æ¥è§¦å¯¼è‡´çš„çƒ§ä¼¤", "description_en": "Burn caused by direct flame contact"}
}

# åˆå§‹åŒ–session state
if 'language' not in st.session_state: st.session_state.language = 'ä¸­æ–‡'
if 'chart_colors' not in st.session_state: st.session_state.chart_colors = ['#4E79A7', '#F28E2B', '#E15759', '#76B7B2', '#59A14F', '#EDC948']
if 'title_font' not in st.session_state: st.session_state.title_font = {'family': 'Microsoft YaHei', 'size': 14, 'weight': 'bold'}
if 'label_font' not in st.session_state: st.session_state.label_font = {'family': 'Microsoft YaHei', 'size': 10}
if 'theme' not in st.session_state: st.session_state.theme = 'light'
if 'data_precision' not in st.session_state: st.session_state.data_precision = 10
if 'chart_title_font' not in st.session_state: st.session_state.chart_title_font = {'family': 'Microsoft YaHei', 'size': 14, 'weight': 'bold'}
if 'chart_axis_font' not in st.session_state: st.session_state.chart_axis_font = {'family': 'Microsoft YaHei', 'size': 10}
if 'chart_tick_font' not in st.session_state: st.session_state.chart_tick_font = {'family': 'Microsoft YaHei', 'size': 8}
if 'chart_label_font' not in st.session_state: st.session_state.chart_label_font = {'family': 'Microsoft YaHei', 'size': 9}

# ä¾§è¾¹æ 
with st.sidebar:
    st.markdown("""
    <div style="text-align: center;">
        <h1>ğŸ”¥ğŸ‘¶</h1>
        <h3>å„¿ç«¥çš®è‚¤æŸä¼¤è¯†åˆ«ç³»ç»Ÿ</h3>
    </div>
    """, unsafe_allow_html=True)
    st.markdown("---")
    app_mode = st.selectbox("é€‰æ‹©åº”ç”¨æ¨¡å¼", ["ğŸ”¬ çƒ§ä¼¤è¯†åˆ«åˆ†æ", "ğŸ“– ä½¿ç”¨æŒ‡å—", "âš™ï¸ ç³»ç»Ÿè®¾ç½®"])
    st.markdown("---")
    if st.session_state.model is not None: 
        st.success("âœ… æ¨¡å‹å·²åŠ è½½")
    else: 
        st.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")

# ä¸»é¡µé¢å†…å®¹
if app_mode == "ğŸ”¬ çƒ§ä¼¤è¯†åˆ«åˆ†æ":
    st.markdown('<div class="main-header">ğŸ”¥ğŸ‘¶ å„¿ç«¥çš®è‚¤æŸä¼¤æ™ºèƒ½è¯†åˆ«ä¸åˆ†æç³»ç»Ÿ</div>', unsafe_allow_html=True)
    
    if st.session_state.model is not None:
        model = st.session_state.model
        st.success("âœ… ä¸“ä¸šæ¨¡å¼ - ä½¿ç”¨è®­ç»ƒå¥½çš„éšæœºæ£®æ—æ¨¡å‹")
    else:
        st.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
        st.stop()
    
    tab1, tab2 = st.tabs(["ğŸ” å•æ ·æœ¬åˆ†æ", "ğŸ“Š æ‰¹é‡åˆ†æ"])
    
    with tab1:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            if st.session_state.language == 'ä¸­æ–‡':
                st.markdown('<div class="sub-header">ğŸ“‹ è¾“å…¥çƒ§ä¼¤ç‰¹å¾å‚æ•°</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div class="sub-header">ğŸ“‹ Input Burn Characteristics</div>', unsafe_allow_html=True)
            
            with st.form("input_form"):
                col1_1, col1_2 = st.columns(2)
                with col1_1:
                    feature1 = st.number_input("BG1 ç”Ÿç‰©æ ‡å¿—ç‰©", value=-7.085353202, format="%.10f", help="ç¬¬ä¸€ä¸ªè¡¨è§‚æ ‡å¿—ç‰©å‚æ•°")
                    feature2 = st.number_input("Ascorbic acid (æŠ—åè¡€é…¸)", value=45874.83777, format="%.10f", help="æŠ—åè¡€é…¸æµ“åº¦")
                    feature3 = st.number_input("Pregnenolone sulfate (å­•çƒ¯é†‡é…®ç¡«é…¸é…¯)", value=31430.32155, format="%.10f", help="å­•çƒ¯é†‡é…®ç¡«é…¸é…¯æµ“åº¦")
                    feature4 = st.number_input("IL-1Î² (pg/mL)", value=422.8258998, format="%.10f", help="ç™½ç»†èƒä»‹ç´ -1Î²æµ“åº¦")
                with col1_2:
                    feature5 = st.number_input("5-Methoxytryptamine (5-ç”²æ°§åŸºè‰²èƒº)", value=23673.82157, format="%.10f", help="5-ç”²æ°§åŸºè‰²èƒºæµ“åº¦")
                    feature6 = st.number_input("EGF (pg/mL)", value=767.7878056, format="%.10f", help="è¡¨çš®ç”Ÿé•¿å› å­æµ“åº¦")
                    feature7 = st.number_input("BG2 ç”Ÿç‰©æ ‡å¿—ç‰©", value=1.106613969, format="%.10f", help="ç¬¬äºŒä¸ªè¡¨è§‚æ ‡å¿—ç‰©å‚æ•°")
                
                if st.session_state.language == 'ä¸­æ–‡':
                    advanced_analysis = st.checkbox("æ‰§è¡ŒSHAP+å›¾ç½‘ç»œ+åäº‹å®åˆ†æ", value=True)
                    submitted = st.form_submit_button("ğŸš€ å¼€å§‹åˆ†æ", use_container_width=True)
                else:
                    advanced_analysis = st.checkbox("Perform SHAP+Graph+Counterfactual Analysis", value=True)
                    submitted = st.form_submit_button("ğŸš€ Start Analysis", use_container_width=True)
        
        with col2:
            if st.session_state.language == 'ä¸­æ–‡':
                st.markdown('<div class="sub-header">ğŸ’¡ å‚æ•°è¯´æ˜</div>', unsafe_allow_html=True)
                st.markdown("""
                <div class="feature-box"><strong>BG1:</strong> å…³é”®ç”Ÿç‰©æ ‡å¿—ç‰©1ï¼Œåæ˜ ç»„ç»‡ç‚ç—‡çŠ¶æ€</div>
                <div class="feature-box"><strong>Ascorbic acid:</strong> æŠ—åè¡€é…¸ï¼ŒæŠ—æ°§åŒ–å‰‚</div>
                <div class="feature-box"><strong>Pregnenolone sulfate:</strong> å­•çƒ¯é†‡é…®ç¡«é…¸é…¯ï¼Œç¥ç»ç±»å›ºé†‡</div>
                <div class="feature-box"><strong>IL-1Î²:</strong> ç‚ç—‡å› å­ï¼Œæµ“åº¦ä¸çƒ§ä¼¤ä¸¥é‡ç¨‹åº¦ç›¸å…³</div>
                <div class="feature-box"><strong>5-Methoxytryptamine:</strong> 5-ç”²æ°§åŸºè‰²èƒºï¼Œç¥ç»é€’è´¨</div>
                <div class="feature-box"><strong>EGF:</strong> è¡¨çš®ç”Ÿé•¿å› å­ï¼Œä¿ƒè¿›ä¼¤å£æ„ˆåˆ</div>
                <div class="feature-box"><strong>BG2:</strong> å…³é”®ç”Ÿç‰©æ ‡å¿—ç‰©2ï¼Œç»„ç»‡ä¿®å¤æŒ‡æ ‡</div>
                """, unsafe_allow_html=True)
        
        if submitted:
            try:
                input_data = pd.DataFrame([[feature1, feature2, feature3, feature4, feature5, feature6, feature7]], 
                                         columns=model.feature_names_in_)
                prediction = model.predict(input_data)[0]
                probabilities = model.predict_proba(input_data)[0]
                
                st.markdown("---")
                if st.session_state.language == 'ä¸­æ–‡':
                    st.markdown('<div class="sub-header">ğŸ“Š åˆ†æç»“æœ</div>', unsafe_allow_html=True)
                else:
                    st.markdown('<div class="sub-header">ğŸ“Š Analysis Results</div>', unsafe_allow_html=True)
                
                col_res1, col_res2, col_res3 = st.columns([1, 2, 1])
                with col_res2:
                    burn_info = burn_type_mapping[prediction]
                    if st.session_state.language == 'ä¸­æ–‡':
                        st.markdown(f"""
                        <div class="prediction-box">
                            <h3>è¯Šæ–­ç»“æœ: {burn_info['cn']}</h3>
                            <p><strong>è‹±æ–‡åç§°:</strong> {burn_info['en']}</p>
                            <p><strong>æè¿°:</strong> {burn_info['description']}</p>
                            <p><strong>ç½®ä¿¡åº¦:</strong> {probabilities[prediction]:.2%}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                        <div class="prediction-box">
                            <h3>Diagnosis Result: {burn_info['en']}</h3>
                            <p><strong>Chinese Name:</strong> {burn_info['cn']}</p>
                            <p><strong>Description:</strong> {burn_info['description_en']}</p>
                            <p><strong>Confidence:</strong> {probabilities[prediction]:.2%}</p>
                        </div>
                        """, unsafe_allow_html=True)
                
                # æ˜¾ç¤º3Dçš®è‚¤æ¨¡å‹
                st.markdown("---")
                if st.session_state.language == 'ä¸­æ–‡':
                    st.markdown('<div class="sub-header">ğŸ§¬ 3Dçš®è‚¤æ¨¡å‹ - çƒ§ä¼¤æ·±åº¦å¯è§†åŒ–</div>', unsafe_allow_html=True)
                else:
                    st.markdown('<div class="sub-header">ğŸ§¬ 3D Skin Model - Burn Depth Visualization</div>', unsafe_allow_html=True)

                # æ·»åŠ çƒ§ä¼¤é¢œè‰²è®¾ç½®
                col_color1, col_color2 = st.columns(2)
                with col_color1:
                    burn_color = st.color_picker("é€‰æ‹©çƒ§ä¼¤åŒºåŸŸé¢œè‰²", "#FF4500", key="burn_color_3d")
                with col_color2:
                    burn_opacity = st.slider("çƒ§ä¼¤åŒºåŸŸé€æ˜åº¦", 0.1, 1.0, 0.7, 0.1, key="burn_opacity_3d")

                # åˆ›å»º3Dçš®è‚¤æ¨¡å‹
                fig_3d = create_skin_3d_model_with_burn_depth(prediction, probabilities, burn_color, burn_opacity)
                st.plotly_chart(fig_3d, use_container_width=True)
                
                if advanced_analysis:
                    if st.session_state.language == 'ä¸­æ–‡':
                        st.markdown('<div class="sub-header">ğŸ”¬ é«˜çº§æ¨¡å‹åˆ†æ</div>', unsafe_allow_html=True)
                    else:
                        st.markdown('<div class="sub-header">ğŸ”¬ Advanced Model Analysis</div>', unsafe_allow_html=True)
                    
                    # SHAPåˆ†æ
                    with st.spinner("æ­£åœ¨è¿›è¡ŒSHAPåˆ†æ..." if st.session_state.language == 'ä¸­æ–‡' else "Performing SHAP analysis..."):
                        shap_results = perform_shap_analysis(model, input_data, model.feature_names_in_)
                    
                    # å›¾ç½‘ç»œåˆ†æ
                    with st.spinner("æ­£åœ¨è¿›è¡Œå›¾ç½‘ç»œåˆ†æ..." if st.session_state.language == 'ä¸­æ–‡' else "Performing graph network analysis..."):
                        graph_results = perform_graph_analysis([feature1, feature2, feature3, feature4, feature5, feature6, feature7], 
                                                              model.feature_names_in_, prediction, burn_type_mapping)
                    
                    # åäº‹å®åˆ†æ
                    if prediction != 0:
                        with st.spinner("æ­£åœ¨è¿›è¡Œåäº‹å®åˆ†æ..." if st.session_state.language == 'ä¸­æ–‡' else "Performing counterfactual analysis..."):
                            counterfactual_results = perform_counterfactual_analysis(model, input_data, prediction, model.feature_names_in_, burn_type_mapping)
                    else:
                        counterfactual_results = {'skip_analysis': True}
                        if st.session_state.language == 'ä¸­æ–‡':
                            st.info("âœ… å½“å‰è¯Šæ–­ä¸ºæ­£å¸¸ç»„ç»‡ï¼Œæ— éœ€è¿›è¡Œåäº‹å®åˆ†æ")
                        else:
                            st.info("âœ… Current diagnosis is normal tissue, counterfactual analysis skipped")
                    
                    # æ˜¾ç¤ºSHAPåˆ†æç»“æœ
                    if shap_results:
                        if st.session_state.language == 'ä¸­æ–‡':
                            st.markdown("##### ğŸ“ˆ SHAPå¤šç±»åˆ«åˆ†æ")
                        else:
                            st.markdown("##### ğŸ“ˆ SHAP Multi-Class Analysis")
                        
                        col_shap1, col_shap2 = st.columns([1, 1])
                        
                        with col_shap1:
                            fig_combined = plot_combined_shap_analysis(shap_results, model.feature_names_in_, burn_type_mapping)
                            if fig_combined:
                                st.pyplot(fig_combined)
                                if st.session_state.language == 'ä¸­æ–‡':
                                    st.caption("å›¾1: SHAPåˆå¹¶åˆ†æ - ç‰¹å¾å½±å“æ–¹å‘å’Œé‡è¦æ€§")
                                else:
                                    st.caption("Figure 1: Combined SHAP Analysis - Feature Impact and Importance")
                        
                        with col_shap2:
                            fig_current = plot_current_prediction_shap(shap_results, model.feature_names_in_, burn_type_mapping)
                            if fig_current:
                                st.pyplot(fig_current)
                                if st.session_state.language == 'ä¸­æ–‡':
                                    st.caption("å›¾2: å½“å‰é¢„æµ‹ç±»åˆ«ç‰¹å¾é‡è¦æ€§åˆ†æ")
                                else:
                                    st.caption("Figure 2: Feature Importance for Current Prediction")
                    
                    # æ˜¾ç¤ºå›¾ç½‘ç»œåˆ†æç»“æœ
                    if graph_results:
                        if st.session_state.language == 'ä¸­æ–‡':
                            st.markdown("##### ğŸ”— ç‰¹å¾å…³è”å›¾ç½‘ç»œåˆ†æ")
                        else:
                            st.markdown("##### ğŸ”— Feature Correlation Graph Analysis")
                        
                        graph_fig = plot_optimized_graph_analysis(graph_results, model.feature_names_in_, burn_info)
                        if graph_fig:
                            st.pyplot(graph_fig)
                    
                    # æ˜¾ç¤ºåäº‹å®åˆ†æç»“æœ
                    if counterfactual_results and not counterfactual_results.get('skip_analysis', False) and counterfactual_results['normal_tissue_suggestions']:
                        if st.session_state.language == 'ä¸­æ–‡':
                            st.markdown("##### ğŸ”„ åäº‹å®åˆ†æä¸æ¢å¤æ­£å¸¸ç»„ç»‡å»ºè®®")
                        else:
                            st.markdown("##### ğŸ”„ Counterfactual Analysis and Normal Tissue Recovery Suggestions")
                        
                        counterfactual_fig = plot_optimized_counterfactual_analysis(counterfactual_results, burn_type_mapping)
                        if counterfactual_fig:
                            st.pyplot(counterfactual_fig)
                        
                        if st.session_state.language == 'ä¸­æ–‡':
                            st.markdown("###### ğŸ’¡ æ¢å¤åˆ°æ­£å¸¸ç»„ç»‡çš„è°ƒæ•´å»ºè®®:")
                            for i, suggestion in enumerate(counterfactual_results['normal_tissue_suggestions'][:3], 1):
                                st.markdown(f"""
                                <div class="analysis-box">
                                <strong>æ–¹æ¡ˆ {i}:</strong> å°† <strong>{suggestion['feature']}</strong> {suggestion['change_direction']}åˆ°åŸæ¥çš„ <strong>{suggestion['required_change']}</strong><br>
                                - åŸå§‹å€¼: {suggestion['original_value']:.10f} â†’ è°ƒæ•´åå€¼: {suggestion['new_value']:.10f}<br>
                                - é¢„æµ‹ç½®ä¿¡åº¦: {suggestion['confidence']:.2%}<br>
                                - æ•ˆæœ: é¢„æµ‹ç»“æœä» <strong>{burn_type_mapping[counterfactual_results['original_prediction']]['cn']}</strong> æ¢å¤åˆ° <strong>æ­£å¸¸ç»„ç»‡</strong>
                                </div>
                                """, unsafe_allow_html=True)
                        else:
                            st.markdown("###### ğŸ’¡ Adjustment suggestions to restore normal tissue:")
                            for i, suggestion in enumerate(counterfactual_results['normal_tissue_suggestions'][:3], 1):
                                st.markdown(f"""
                                <div class="analysis-box">
                                <strong>Scenario {i}:</strong> Change <strong>{suggestion['feature']}</strong> to <strong>{suggestion['required_change']}</strong> of original<br>
                                - Original value: {suggestion['original_value']:.10f} â†’ Adjusted value: {suggestion['new_value']:.10f}<br>
                                - Prediction confidence: {suggestion['confidence']:.2%}<br>
                                - Effect: Prediction changes from <strong>{burn_type_mapping[counterfactual_results['original_prediction']]['en']}</strong> to <strong>Normal Tissue</strong>
                                </div>
                                """, unsafe_allow_html=True)
                    
                    # æ¦‚ç‡åˆ†å¸ƒå›¾
                    st.markdown("---")
                    if st.session_state.language == 'ä¸­æ–‡':
                        st.markdown('<div class="sub-header">ğŸ“ˆ æ¦‚ç‡åˆ†å¸ƒåˆ†æ</div>', unsafe_allow_html=True)
                    else:
                        st.markdown('<div class="sub-header">ğŸ“ˆ Probability Distribution Analysis</div>', unsafe_allow_html=True)
                    
                    font_settings = get_chart_font_settings()
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
                    if st.session_state.language == 'ä¸­æ–‡':
                        title1, title2, ylabel = 'çƒ§ä¼¤ç±»å‹æ¦‚ç‡åˆ†å¸ƒ', 'æ¦‚ç‡åˆ†å¸ƒé¥¼å›¾', 'æ¦‚ç‡'
                        labels = [burn_type_mapping[i]['cn'] for i in range(len(probabilities))]
                    else:
                        title1, title2, ylabel = 'Burn Type Probability Distribution', 'Probability Distribution Pie Chart', 'Probability'
                        labels = [burn_type_mapping[i]['en'] for i in range(len(probabilities))]
                    
                    colors = st.session_state.chart_colors[:len(probabilities)]
                    bars = ax1.bar(range(len(probabilities)), probabilities, color=colors)
                    ax1.set_title(title1, fontfamily=font_settings['title_font']['family'], fontsize=font_settings['title_font']['size'])
                    ax1.set_xticks(range(len(probabilities)))
                    ax1.set_xticklabels(labels, rotation=45, ha='right', fontfamily=font_settings['tick_font']['family'])
                    ax1.set_ylabel(ylabel, fontfamily=font_settings['axis_font']['family'], fontsize=font_settings['axis_font']['size'])
                    ax1.set_ylim(0, 1)
                    
                    for bar in bars:
                        height = bar.get_height()
                        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01, f'{height:.1%}', 
                                ha='center', va='bottom', fontfamily=font_settings['label_font']['family'])
                    
                    ax2.pie(probabilities, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90,
                           textprops={'fontfamily': font_settings['label_font']['family']})
                    ax2.set_title(title2, fontfamily=font_settings['title_font']['family'],
                                 fontsize=font_settings['title_font']['size'])
                    
                    apply_chart_font_settings(ax1, title=title1, ylabel=ylabel)
                    apply_chart_font_settings(ax2, title=title2)
                    
                    plt.tight_layout()
                    st.pyplot(fig)
                    
                    # ç»“æœå¯¼å‡º
                    st.markdown("---")
                    if st.session_state.language == 'ä¸­æ–‡':
                        st.markdown('<div class="sub-header">ğŸ’¾ ç»“æœå¯¼å‡º</div>', unsafe_allow_html=True)
                    else:
                        st.markdown('<div class="sub-header">ğŸ’¾ Export Results</div>', unsafe_allow_html=True)
                    
                    # ç”Ÿæˆå¢å¼ºçš„åŒ»ç–—æŠ¥å‘Š
                    report_text = generate_medical_report(input_data, prediction, probabilities, shap_results, graph_results, counterfactual_results, burn_type_mapping, model.feature_names_in_, st.session_state.language)
                    
                    col_exp1, col_exp2, col_exp3 = st.columns(3)
                    with col_exp1:
                        csv_data = input_data.copy()
                        csv_data['é¢„æµ‹ç±»å‹' if st.session_state.language == 'ä¸­æ–‡' else 'Predicted Type'] = burn_info['cn' if st.session_state.language == 'ä¸­æ–‡' else 'en']
                        csv_data['ç½®ä¿¡åº¦' if st.session_state.language == 'ä¸­æ–‡' else 'Confidence'] = probabilities[prediction]
                        csv = csv_data.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="ğŸ“¥ å¯¼å‡ºCSV" if st.session_state.language == 'ä¸­æ–‡' else "ğŸ“¥ Export CSV",
                            data=csv, file_name="burn_analysis_result.csv", mime="text/csv", use_container_width=True
                        )
                    with col_exp2:
                        buf = io.BytesIO()
                        fig.savefig(buf, format="png", dpi=300, bbox_inches='tight')
                        st.download_button(
                            label="ğŸ–¼ï¸ å¯¼å‡ºå›¾è¡¨" if st.session_state.language == 'ä¸­æ–‡' else "ğŸ–¼ï¸ Export Chart",
                            data=buf.getvalue(), file_name="burn_analysis_chart.png", mime="image/png", use_container_width=True
                        )
                    with col_exp3:
                        st.download_button(
                            label="ğŸ“„ å¯¼å‡ºåŒ»ç–—æŠ¥å‘Š" if st.session_state.language == 'ä¸­æ–‡' else "ğŸ“„ Export Medical Report",
                            data=report_text.encode('utf-8'), file_name="burn_medical_report.txt", mime="text/plain", use_container_width=True
                        )
                    
            except Exception as e:
                st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")

    with tab2:
        if st.session_state.language == 'ä¸­æ–‡':
            st.markdown('<div class="sub-header">ğŸ“ æ‰¹é‡æ•°æ®å¤„ç†</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="sub-header">ğŸ“ Batch Data Processing</div>', unsafe_allow_html=True)
        st.info("æ‰¹é‡åˆ†æåŠŸèƒ½å¼€å‘ä¸­...")

elif app_mode == "ğŸ“– ä½¿ç”¨æŒ‡å—":
    st.markdown('<div class="main-header">ğŸ“– ä½¿ç”¨æŒ‡å—</div>', unsafe_allow_html=True)
    
    tab_guide1, tab_guide2, tab_guide3, tab_guide4, tab_guide5 = st.tabs(["ğŸ“‹ ç³»ç»Ÿä»‹ç»", "ğŸ”¬ ä½¿ç”¨æ­¥éª¤", "ğŸ“Š æ•°æ®è¯´æ˜", "ğŸ§  ç®—æ³•åŸç†", "â“ å¸¸è§é—®é¢˜"])
    with tab_guide1:
        st.markdown('<div class="guide-section">', unsafe_allow_html=True)
        st.markdown("## ğŸ”¬ ç³»ç»Ÿä»‹ç»")
        st.markdown("""
        æœ¬ç³»ç»ŸåŸºäºæœºå™¨å­¦ä¹ ç®—æ³•ï¼Œé€šè¿‡å¯¹ç”Ÿç‰©æ ‡å¿—ç‰©çš„åˆ†æï¼Œå®ç°çƒ§ä¼¤ç±»å‹çš„æ™ºèƒ½è¯†åˆ«å’Œåˆ†ç±»ã€‚ç³»ç»Ÿé›†æˆäº†å…ˆè¿›çš„æ¨¡å‹å¯è§£é‡Šæ€§æŠ€æœ¯ï¼Œ
        åŒ…æ‹¬SHAPåˆ†æã€å›¾ç½‘ç»œåˆ†æå’Œåäº‹å®åˆ†æï¼Œä¸ºåŒ»ç–—ä¸“ä¸šäººå‘˜æä¾›å…¨é¢çš„å†³ç­–æ”¯æŒã€‚
        """)
        st.markdown('</div>', unsafe_allow_html=True)
        
        col_intro1, col_intro2 = st.columns(2)
    with col_intro1:
        st.markdown('<div class="feature-box">', unsafe_allow_html=True)
        st.markdown("### ğŸ¯ ç³»ç»Ÿç‰¹è‰²")
        st.markdown("""
        - **æ™ºèƒ½è¯†åˆ«**: åŸºäºéšæœºæ£®æ—ç®—æ³•çš„å¤šåˆ†ç±»æ¨¡å‹
        - **å¯è§£é‡Šæ€§**: é›†æˆSHAPã€å›¾ç½‘ç»œã€åäº‹å®åˆ†æ
        - **é«˜ç²¾åº¦**: æ”¯æŒå°æ•°ç‚¹å10ä½çš„æ•°æ®ç²¾åº¦
        - **å¯è§†åŒ–**: ä¸°å¯Œçš„å›¾è¡¨å’Œäº¤äº’ç•Œé¢
        - **å¤šè¯­è¨€**: æ”¯æŒä¸­è‹±æ–‡ç•Œé¢åˆ‡æ¢
        """)
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col_intro2:
        st.markdown('<div class="feature-box">', unsafe_allow_html=True)
        st.markdown("### ğŸ“Š åŠŸèƒ½æ¨¡å—")
        st.markdown("""
        - **å•æ ·æœ¬åˆ†æ**: å•ä¸ªæ ·æœ¬çš„è¯¦ç»†åˆ†æ
        - **æ‰¹é‡åˆ†æ**: æ‰¹é‡æ•°æ®å¤„ç†åŠŸèƒ½
        - **é«˜çº§åˆ†æ**: SHAP+å›¾ç½‘ç»œ+åäº‹å®åˆ†æ
        - **ç»“æœå¯¼å‡º**: æ”¯æŒCSVã€å›¾è¡¨ã€æŠ¥å‘Šå¯¼å‡º
        - **ç³»ç»Ÿè®¾ç½®**: ä¸ªæ€§åŒ–ç•Œé¢é…ç½®
        """)
        st.markdown('</div>', unsafe_allow_html=True)

elif app_mode == "âš™ï¸ ç³»ç»Ÿè®¾ç½®":
    st.markdown('<div class="main-header">âš™ï¸ ç³»ç»Ÿè®¾ç½®</div>', unsafe_allow_html=True)
    
    # è¯­è¨€è®¾ç½®
    st.subheader("ğŸŒ è¯­è¨€è®¾ç½®")
    language = st.selectbox("é€‰æ‹©ç•Œé¢è¯­è¨€", ["ä¸­æ–‡", "English"], key="language_select")
    
    if st.button("ğŸ’¾ åº”ç”¨è¯­è¨€è®¾ç½®", use_container_width=True):
        st.session_state.language = language
        st.success("âœ… è¯­è¨€è®¾ç½®å·²åº”ç”¨")
    
    st.markdown("---")
    
    # å›¾è¡¨é¢œè‰²è®¾ç½®
    st.subheader("ğŸ¨ å›¾è¡¨é¢œè‰²è®¾ç½®")
    st.info("å½“å‰ä½¿ç”¨Natureé…è‰²æ–¹æ¡ˆ: #4E79A7, #F28E2B, #E15759, #76B7B2, #59A14F, #EDC948")
    
    # åº”ç”¨è®¾ç½®æŒ‰é’®
    if st.button("ğŸ’¾ åº”ç”¨æ‰€æœ‰è®¾ç½®", use_container_width=True):
        st.success("âœ… æ‰€æœ‰è®¾ç½®å·²åº”ç”¨")
    
    # é‡ç½®è®¾ç½®ä¸ºé»˜è®¤å€¼
    if st.button("ğŸ”„ é‡ç½®ä¸ºé»˜è®¤è®¾ç½®", use_container_width=True):
        st.session_state.chart_colors = ['#4E79A7', '#F28E2B', '#E15759', '#76B7B2', '#59A14F', '#EDC948']
        st.session_state.title_font = {'family': 'Microsoft YaHei', 'size': 14, 'weight': 'bold'}
        st.session_state.label_font = {'family': 'Microsoft YaHei', 'size': 10}
        st.session_state.current_data_precision = 10
        st.session_state.theme = 'light'
        st.success("âœ… å·²é‡ç½®ä¸ºé»˜è®¤è®¾ç½®")
    
    st.markdown("---")
    st.markdown('<div style="text-align: center; color: #666; font-family: "Microsoft YaHei", sans-serif;">ğŸ‘¶ å„¿ç«¥çš®è‚¤æŸä¼¤è¯†åˆ«ç³»ç»Ÿ | åŸºäºæœºå™¨å­¦ä¹ çš„åŒ»ç–—è¾…åŠ©è¯Šæ–­å·¥å…· | v1.0 | æœ¬åœ°ä¸“ä¸šç‰ˆæœ¬</div>', unsafe_allow_html=True)